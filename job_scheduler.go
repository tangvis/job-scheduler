package jobscheduler

import (
	"context"
	"errors"
	"fmt"
	"github.com/tangvis/job-scheduler/dag"
	"runtime"
	"strings"
	"sync"
	"time"

	"go.uber.org/atomic"
	"golang.org/x/sync/errgroup"
	"golang.org/x/sync/semaphore"
)

const (
	lockKey          = "lock_key"
	defaultMaxWorker = 10000
	defaultTimeout   = 10
)

// GigaI
// ä¸åŒçš„ä¸šåŠ¡éƒ½å¯ä»¥å®ç°è‡ªå·±çš„gigaæ¥ä½¿ç”¨ç¼–æ’æ¡†æ¶
type GigaI interface {
	Ctx() context.Context
	Err() error
	Cancel()
	AppendError(err error, name string)
	RegisterProcessor(processor ...*Processor)
	GetProcessor(idx int) *Processor
	GetAllProcessors() map[int]*Processor
	ErrGroup() *errgroup.Group
	ConcurrencyRun(p *Processor)
	WaitingQueue() chan *Processor
	AddWaitingProcessor(p *Processor)
	SetWaitingQueue()

	BizData() interface{}
	Name() string
}

// RunGiga
// å¯åŠ¨giga
func RunGiga(giga GigaI) error {
	defer func() {
		if giga.Err() != nil {
			fmt.Printf("RunGiga Error: %s", giga.Err().Error())
		}
	}()
	go func() {
		for _, processor := range giga.GetAllProcessors() {
			if !processor.NoDependence() {
				continue
			}
			giga.AddWaitingProcessor(processor)
		}
	}()
	if err := loopWaitingProcessorQueue(giga); err != nil {
		return err
	}

	return giga.ErrGroup().Wait()
}

func loopWaitingProcessorQueue(giga GigaI) error {
	for {
		select {
		case <-giga.Ctx().Done():
			return giga.Ctx().Err()
		case waitingProcessor, ok := <-giga.WaitingQueue():
			if !ok { // å¦‚æœchannelå…³é—­ï¼Œåˆ™é€€å‡ºå¾ªç¯
				return nil
			}
			giga.ConcurrencyRun(waitingProcessor)
		}
	}
}

// BaseGiga
// ä½œä¸šæ‰§è¡Œå‘¨æœŸå†…çš„ä¸Šä¸‹æ–‡
// å¯ä»¥ç†è§£æˆä¸€ä¸ªå·¥å‚ï¼Œå·¥äººå°±æ˜¯processorï¼Œå·¥äººéœ€è¦çš„å·¥å…·ã€åŸææ–™ä»¥åŠç”Ÿäº§çš„æˆå“éƒ½åœ¨gigaé‡Œé¢ï¼Œå·¥äººä¸éœ€è¦å¯¹å·¥å‚å¤–æœ‰ä»»ä½•è”ç³»
// gigaéœ€è¦æä¾›çš„åŠŸèƒ½å°±æ˜¯ï¼šä½œä¸šæ‰€éœ€çš„ğŸ”§ã€åŸæ–™ä»¥åŠç»„è£…æˆå“ï¼Œå¤–ç•Œæ²Ÿé€šçš„ä»£ç†ï¼šæ—¥å¿—ã€æ‰“ç‚¹ç­‰
// ä¸šåŠ¡æ— å…³ï¼Œå…·ä½“çš„æ¨¡å—å¯ä»¥æ ¹æ®è‡ªå·±éœ€æ±‚å®ç°gigaï¼Œç»§æ‰¿base giga
type BaseGiga struct {
	ctx    context.Context
	cancel func()

	errGroup *errgroup.Group
	weighted *semaphore.Weighted
	// channelå¤§å°ä¸ºremainProcessors
	// è®¾ç½®ä¸ºè¿™ä¸ªå¤§å°çš„åŸå› æ˜¯ä¸ºäº†é˜²æ­¢æ­»é”ï¼Œå› ä¸ºæˆ‘ä»¬chançš„ç”Ÿäº§æ–¹æœ‰ä¸¤ä¸ªï¼Œä¸€ä¸ªæ˜¯åˆå§‹å¯åŠ¨çš„æ—¶å€™å…¥åº¦ä¸º0çš„èŠ‚ç‚¹ä¼šè¢«æ”¾è¿›chan
	// ç¬¬äºŒä¸ªæ˜¯æˆ‘ä»¬çš„processorå¤„ç†å®Œæˆåä¼šæ£€æŸ¥åç»§èŠ‚ç‚¹æ˜¯ä¸æ˜¯å…¥åº¦å˜ä¸º0äº†ï¼Œæ˜¯çš„è¯å°±æ”¾è¿›chan
	// åŒæ—¶æ¶ˆè´¹ç«¯å—åˆ°æœ€å¤§åç¨‹æ•°é…ç½®çš„é™åˆ¶ï¼Œè€Œç”Ÿäº§ç«¯çš„processoræ­£æ˜¯åç¨‹æ•°é‡çš„å ç”¨æ–¹ï¼Œå› æ­¤ä¸ºäº†ä¿è¯æˆ‘ä»¬çš„processor
	// ä¸€å®šèƒ½æ”¾å…¥chanï¼Œæˆ‘ä»¬åˆå§‹åŒ–ä¸ºprocessorçš„æ€»æ•°é‡
	processorQueue   chan *Processor
	remainProcessors atomic.Int64 // å‰©ä½™æœªæ‰§è¡Œçš„processorä¸ªæ•°

	processors map[int]*Processor

	err error
	// mutexesé”æ± 
	mutexes sync.Map
}

func (giga *BaseGiga) Ctx() context.Context {
	return giga.ctx
}

func (giga *BaseGiga) Err() error {
	return giga.err
}

func (giga *BaseGiga) GetProcessor(idx int) *Processor {
	return giga.processors[idx]
}

func (giga *BaseGiga) RegisterProcessor(processor ...*Processor) {
	for _, p := range processor {
		giga.processors[p.id] = p
		giga.remainProcessors.Add(1)
	}
}

func (giga *BaseGiga) GetAllProcessors() map[int]*Processor {
	return giga.processors
}

func (giga *BaseGiga) ErrGroup() *errgroup.Group {
	return giga.errGroup
}

func (giga *BaseGiga) WaitingQueue() chan *Processor {
	return giga.processorQueue
}

func (giga *BaseGiga) AddWaitingProcessor(p *Processor) {
	giga.processorQueue <- p
	if giga.remainProcessors.Dec() == 0 {
		close(giga.processorQueue)
	}
}

func (giga *BaseGiga) SetWaitingQueue() {
	giga.processorQueue = make(chan *Processor, giga.remainProcessors.Load())
}

// ConcurrencyRun
// å¹¶å‘æ‰§è¡Œprocessor
func (giga *BaseGiga) ConcurrencyRun(p *Processor) {
	// è·å–åç¨‹è®¸å¯
	err := giga.weighted.Acquire(giga.ctx, 1)
	if err != nil {
		p.Abort(err)
	}
	giga.ErrGroup().Go(func() error {
		defer func() {
			if ev := recover(); ev != nil {
				p.Abort(fmt.Errorf("panic"))
				stack := make([]byte, 16*1024)
				_ = runtime.Stack(stack, false)
				fmt.Printf("[PANIC]%+v, %s\n", ev, stack)
				return
			}
			giga.weighted.Release(1)
		}()
		// æ‰§è¡Œæ‹¦æˆªå™¨é“¾
		p.exe()
		return giga.Err()
	})

}

func NewBaseGiga(originCtx context.Context, config JobConfig) BaseGiga {
	if config.MaxWorker == 0 { // æ²¡æœ‰ä¼ å°±é»˜è®¤ä¸é™åˆ¶åç¨‹æ•°é‡
		config.MaxWorker = defaultMaxWorker
	}
	if config.Timeout == 0 {
		config.Timeout = defaultTimeout
	}
	timeoutCtx, timeoutCancel := context.WithTimeout(originCtx, config.Timeout*time.Second)
	g, ctx := errgroup.WithContext(timeoutCtx)
	ctx, cancel := context.WithCancel(ctx)
	return BaseGiga{
		ctx: ctx,
		cancel: func() {
			cancel()
			timeoutCancel()
		},
		err:        nil,
		errGroup:   g,
		weighted:   semaphore.NewWeighted(config.MaxWorker),
		processors: map[int]*Processor{},
	}
}

func (giga *BaseGiga) Cancel() {
	if giga.cancel != nil {
		giga.cancel()
	}
}

func (giga *BaseGiga) AppendError(err error, name string) {
	mutex, _ := giga.mutexes.LoadOrStore(lockKey, &sync.Mutex{})
	mutex.(*sync.Mutex).Lock()
	defer mutex.(*sync.Mutex).Unlock()
	wrappedErr := fmt.Errorf("processor:%s, err:%w", name, err)
	if giga.err != nil {
		giga.err = fmt.Errorf("%w;%s", giga.err, wrappedErr.Error())
		return
	}
	giga.err = wrappedErr
}

type Invoker func(giga GigaI) error

func (i Invoker) Invoke(giga GigaI) error {
	return i(giga)
}

// InvokerGroup æœªæ¥æ‰©å±•ç‰¹æ€§ï¼Œå¤šä¸ªinvokerä¹Ÿå¯ä»¥ç»„æˆä¸€ä¸ªgroupç»„è£…è¿›åŒä¸€ä¸ªprocessor
type InvokerGroup []Invoker

func (group InvokerGroup) ConvToInvoker() Invoker {
	return func(giga GigaI) error {
		for _, invoker := range group {
			if err := invoker(giga); err != nil {
				return err
			}
		}
		return nil
	}
}

// Processor
// ä½œä¸šæ‰§è¡Œå™¨
// å¯ä»¥ç†è§£æˆå·¥äººï¼Œå¯ä»¥åœ¨gigaè¿›è¡Œå„ç§åŠ å·¥å’Œç”Ÿäº§åŠ¨ä½œ
type Processor struct {
	giga GigaI

	unaryIntChain UnaryIntChain // æ‹¦æˆªå™¨é“¾ï¼Œæœ€åä¸€ä¸ªå…ƒç´ å›ºå®šæ˜¯å®é™…çš„ä¸šåŠ¡å¤„ç†å‡½æ•°
	intIndex      int           // æ‹¦æˆªå™¨ç´¢å¼•

	notifier     *Notifier   // å½“å‰èŠ‚ç‚¹çš„é€šçŸ¥å™¨
	depNotifiers []*Notifier // ä¸‹æ¸¸èŠ‚ç‚¹notifieråˆ—è¡¨

	RetryManager RequestRetryManager

	name string
	id   int

	err error
}

func (p *Processor) Reset(giga GigaI, id int, name string) {
	p.giga = giga
	p.unaryIntChain = make([]UnaryProcessorInterceptor, 0)
	p.intIndex = -1
	p.notifier.Reset()
	p.depNotifiers = p.depNotifiers[:0]
	p.RetryManager = nil
	p.name = name
	p.id = id
	p.err = nil
}

func (p *Processor) Release() {
	ResourcePool.ProcessorPool.Put(p)
}

func GetProcessorFromPool(giga GigaI, id int, name string) *Processor {
	processor := ResourcePool.ProcessorPool.Get().(*Processor)
	processor.Reset(giga, id, name)
	return processor
}

func NewProcessor(giga GigaI, id int, name string) *Processor {
	p := &Processor{
		giga:     giga,
		intIndex: -1,
		name:     name,
		id:       id,
		notifier: NewNotifier(),
	}
	p.notifier.SetProcessor(p)
	return p
}

// SetUpstream
// @Description: è®¾ç½®ä¸Šæ¸¸èŠ‚ç‚¹
func (p *Processor) SetUpstream(processor *Processor) {
	processor.RegisterDepNotifiers(p.notifier)
	p.notifier.Inc()
}

// RegisterInterceptor
// @Description: æ³¨å†Œæ‹¦æˆªå™¨
func (p *Processor) RegisterInterceptor(int ...UnaryProcessorInterceptor) {
	// åæ³¨å†Œçš„æ‹¦æˆªå™¨å…ˆæ‰§è¡Œ
	p.unaryIntChain = append(int, p.unaryIntChain...)
}

// RegisterCoreExecutor
// @Description: æ³¨å†Œæ ¸å¿ƒå¤„ç†å‡½æ•°
func (p *Processor) RegisterCoreExecutor(invokers ...Invoker) {
	invoker := InvokerGroup(invokers).ConvToInvoker()
	p.unaryIntChain = append(p.unaryIntChain,
		func(processor *Processor) {
			var err error
			// é‡è¯•é€»è¾‘
			for {
				err = invoker(processor.giga)
				if p.RetryManager == nil {
					break
				}
				if err == nil || !p.RetryManager(p.giga, err) {
					break
				}
			}
			if err != nil {
				processor.Abort(err)
			}
		})
}

// Exe
// @Description: æ‰§è¡Œ
func (p *Processor) Exe(giga GigaI) {
	select {
	// gigaçš„cancelä¿¡å·
	case <-giga.Ctx().Done():
		// è®¾ç½®contextè¶…æ—¶ä¸ºå½“å‰processorçš„é”™è¯¯
		p.err = giga.Ctx().Err()
		return
	default:
	}
	giga.ConcurrencyRun(p)
}

func (p *Processor) exe() {
	p.Next()
	// å¦‚æœæ•´ä¸ªgigaæœ‰é”™è¯¯ï¼Œç›´æ¥é€€å‡º
	if p.giga.Err() != nil {
		return
	}
	// é€šçŸ¥ä¸‹æ¸¸
	p.Notify()
}

// Abort
// @Description: ä¸­æ–­æ•´ä¸ªgigaçš„æ‰§è¡Œ
// @param err: ç”¨æ¥è®¾ç½®å½“å‰processorçš„é”™è¯¯ä»¥åŠgigaçš„é”™è¯¯
func (p *Processor) Abort(err error) {
	p.giga.Cancel()
	if err != nil {
		p.giga.AppendError(err, p.name)
		p.err = err
	}
}

// RegisterDepNotifiers
// @Description: æ³¨å†Œä¸‹æ¸¸èŠ‚ç‚¹çš„é€šçŸ¥å™¨
func (p *Processor) RegisterDepNotifiers(notifiers ...*Notifier) {
	p.depNotifiers = append(notifiers, p.depNotifiers...)
}

// Notify
// @Description: ä¾èµ–é€šçŸ¥ï¼Œå¦‚æœæœ‰å…¶ä»–processorä¾èµ–æœ¬processorçš„å¤„ç†ï¼Œé€šè¿‡è¿™ä¸ªæ¥å£è¿›è¡Œé€šçŸ¥
func (p *Processor) Notify() {
	for _, notifier := range p.depNotifiers {
		notifier.Dec()
	}
}

// NoDependence
// @Description: å½“å‰èŠ‚ç‚¹æ˜¯å¦æ²¡æœ‰ä¸Šæ¸¸ä¾èµ–
func (p *Processor) NoDependence() bool {
	return p.notifier.NoDependence()
}

// Next
// same as gin
// @Description: æ‰§è¡Œä¸‹ä¸€ä¸ªæ‹¦æˆªå™¨
func (p *Processor) Next() {
	p.intIndex++
	for p.intIndex < len(p.unaryIntChain) {
		p.unaryIntChain[p.intIndex](p)
		p.intIndex++
	}
}

type UnaryProcessorInterceptor func(p *Processor)
type UnaryIntChain []UnaryProcessorInterceptor

type Notifier struct {
	processor *Processor
	degree    *atomic.Int64
}

// Dec
// @Description: å½“å‰é€šçŸ¥å™¨çš„åº¦-1ï¼Œå¦‚æœåº¦ä¸º0ï¼Œåˆ™æ”¾å…¥å¾…å¯åŠ¨é˜Ÿåˆ—
func (notifier *Notifier) Dec() {
	if notifier.degree.Dec() == 0 {
		notifier.processor.giga.AddWaitingProcessor(notifier.processor)
	}
}

// Inc
// @Description: å½“å‰é€šçŸ¥å™¨çš„åº¦+1
func (notifier *Notifier) Inc() {
	notifier.degree.Inc()
}

// NoDependence
// @Description: å½“å‰é€šçŸ¥å™¨çš„åº¦æ˜¯å¦==0
func (notifier *Notifier) NoDependence() bool {
	return notifier.degree.Load() == 0
}

func (notifier *Notifier) Reset() {
	notifier.degree = atomic.NewInt64(0)
}

func (notifier *Notifier) SetProcessor(p *Processor) {
	notifier.processor = p
}

func NewNotifier() *Notifier {
	return &Notifier{}
}

var interceptorFactory = NewInterceptorFactory()

// BuildScheduleJobs
// @Description: ä»dagç»„è£…ç¼–æ’ä½œä¸š
// @param ctx
// @param dag è§£æå¥½çš„dagå›¾
// @return *Giga gigaå·¥å‚
// @return error
// nolint
func BuildScheduleJobs(giga GigaI, dag *dag.DAG, bizFuncCollection map[string]Invoker) (GigaI, func(), error) {
	toReleaseProcessors := make([]*Processor, 0)
	releaseFunc := func() {
		for _, processor := range toReleaseProcessors {
			if processor != nil {
				processor.Release()
			}
		}
	}
	isCycle, err := dag.ValidateCycle()
	if err != nil {
		return nil, releaseFunc, err
	}
	if isCycle {
		return nil, releaseFunc, DagHasCycleErr
	}
	for _, vertex := range dag.GetAllVertex() {
		// åˆ›å»ºprocessor
		config, ok := vertex.Value.(ConfigEntity)
		if !ok {
			return nil, releaseFunc, JobConfigNotLegalErr(vertex.Value)
		}
		funcGroup := config.FuncGroup
		p := GetProcessorFromPool(giga, vertex.ID, strings.Join([]string{giga.Name(), strings.Join(funcGroup, "->")}, ":"))
		toReleaseProcessors = append(toReleaseProcessors, p)
		// æ³¨å†Œprocessor
		giga.RegisterProcessor(p)
		// è·å–processorå¯¹åº”çš„ä¸šåŠ¡å¤„ç†å‡½æ•°
		var fs InvokerGroup
		for _, funcName := range funcGroup {
			f, ok := bizFuncCollection[funcName]
			if !ok {
				return nil, releaseFunc, JobFuncNotFoundErr(vertex.Value.(string))
			}
			fs = append(fs, f)
		}
		// æ³¨å†Œä¸šåŠ¡å¤„ç†å‡½æ•°
		p.RegisterCoreExecutor(fs...)
		ProcessorRegisterInterceptors(p, config)
	}
	giga.SetWaitingQueue() // åœ¨processorå…¨éƒ¨æ³¨å†Œå®Œæˆä¹‹åï¼Œåˆ›å»ºwaiting queueï¼Œç›®çš„æ˜¯waiting queueçš„å¤§å°éœ€è¦å¤§äºç­‰äºprocessorçš„ä¸ªæ•°
	for _, vertex := range dag.GetAllVertex() {
		// ä»gigaè·å–å·²æ³¨å†Œçš„processor
		p := giga.GetProcessor(vertex.ID)
		// ä»dagå›¾è·å–processorçš„ä¸Šæ¸¸ä¾èµ–èŠ‚ç‚¹
		predecessors, err := dag.Predecessors(vertex)
		if err != nil {
			return nil, releaseFunc, err
		}
		for _, predecessor := range predecessors {
			// ä¾æ¬¡æ³¨å†Œä¸Šæ¸¸ä¾èµ–èŠ‚ç‚¹
			p.SetUpstream(giga.GetProcessor(predecessor.ID))
		}
	}
	return giga, releaseFunc, nil
}

// ProcessorRegisterInterceptors
// æ³¨å†Œå…¶ä»–æ‹¦æˆªå™¨ï¼ˆæ—¥å¿—ï¼Œæ‰“ç‚¹ç­‰ï¼‰
// todo é€šè¿‡mapé…ç½®åŒ–
func ProcessorRegisterInterceptors(p *Processor, config ConfigEntity) {
	if !config.IgnoreCat {
		p.RegisterInterceptor(interceptorFactory.NewCatInterceptor())
	}
	if !config.IgnoreLog {
		p.RegisterInterceptor(interceptorFactory.NewLogInterceptor())
	}
}

func ParseConfig(ctx context.Context, config JobConfig) (*dag.DAG, error) {
	if err := validateConfig(config); err != nil {
		return nil, err
	}
	d := dag.NewDAG()
	for _, configEntity := range config.Configs {
		d.AddVertex(dag.NewVertex(configEntity.ID, configEntity))
	}
	for _, configEntity := range config.Configs {
		for _, prev := range configEntity.Prev {
			tail, err := d.GetVertex(prev)
			if errors.Is(err, dag.VNEErr) {
				fmt.Printf("prev processor id (%d) not exists\n", prev)
				continue
			}
			if err != nil {
				return nil, err
			}
			head, err := d.GetVertex(configEntity.ID)
			if err != nil {
				return nil, err
			}
			if err = d.AddEdge(tail, head); err != nil {
				return nil, err
			}
		}
	}
	return d, nil
}

func validateConfig(config JobConfig) error {
	if len(config.Configs) == 0 {
		return EmptyConfigErr
	}
	m := make(map[int]struct{})
	for _, configEntity := range config.Configs {
		m[configEntity.ID] = struct{}{}
	}
	if len(m) != len(config.Configs) {
		return IDDuplicatedErr
	}
	return nil
}
